{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GztdoSJiAqF1"
      },
      "outputs": [],
      "source": [
        "#@title Install prerequsite: you may have to do Runtime -> Restart runtime after the installation\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade setuptools wheel\n",
        "!pip install --upgrade \"mxnet<2.0.0\"\n",
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8VaE4FjdJSf"
      },
      "outputs": [],
      "source": [
        "import autogluon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_mQlXl4BnDA",
        "outputId": "841e9bc2-181b-4470-fb4d-112d9c3a65c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive (You don't need to run this if you are running notebooks on your laptop)\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# The following command will prompt a URL for you to click and obtain the\n",
        "# authorization code\n",
        "\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQD4mkx-CCmA"
      },
      "outputs": [],
      "source": [
        "# Set up data folder\n",
        "from pathlib import Path\n",
        "\n",
        "# Change this to where you put your hw2 files\n",
        "DATA = Path(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVpMokdnR08U"
      },
      "source": [
        "## Problem 2: Classifying Skin Sample Source Using Transcriptomic Profile\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCIkTJEDlwnN"
      },
      "source": [
        "In Problem 1, we have done differential expression between sun-exposed skin and non-exposed skin. As we see a distinct transcriptomic pattern in these two types of samples, we will try to build a binary classification model, that given an transcriptomic profile of a skin sample, we can prodict the whether the skin has been exposed to the sun or not.\n",
        "\n",
        "We'll use the log2 CPM values generated from DGEList to build our model. \n",
        "\n",
        "We'll also load the meta data and clean up some columns as we did in Problem 1 and extract sample IDs that match the column names of the expression table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TCbmVGlXQNa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "gefile = DATA / \"normal_gtex_subset_rnaseq_tmm_logcpm.txt\"\n",
        "metafile = DATA / \"gtex_subset_sample_sheet.txt\"\n",
        "\n",
        "ge = pd.read_csv(gefile, sep=\"\\t\", index_col=0)\n",
        "meta = pd.read_csv(metafile, sep=\"\\t\", index_col=\"SAMPID\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nS-HMjWRUK7"
      },
      "source": [
        "As in Problem 1, we are only interested in skin samples. We will also create a biinary target variable indicating whether the sample was from sun-exposed skin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8YO870ZhSiR"
      },
      "outputs": [],
      "source": [
        "# Align the samples in two files\n",
        "meta = meta[\n",
        "    meta.SMTSD.isin(\n",
        "        {\"Skin - Not Sun Exposed (Suprapubic)\", \n",
        "         \"Skin - Sun Exposed (Lower leg)\"}\n",
        "    )\n",
        "]\n",
        "common_samples = list(set(meta.index) & set(ge.columns))\n",
        "meta = meta.loc[common_samples]\n",
        "ge = ge.loc[:, common_samples]\n",
        "\n",
        "meta[\"sun_exposed\"] = 1\n",
        "meta.loc[meta.SMTSD == \"Skin - Not Sun Exposed (Suprapubic)\", \"sun_exposed\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd7rb2r8Rq_g",
        "outputId": "a469ecb4-a412-49ba-d352-cb33a21abe96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sun_exposed\n",
              "0    52\n",
              "1    60\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count patients per group\n",
        "meta.groupby(\"sun_exposed\").size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtRVGnInZx-q"
      },
      "source": [
        "### Split test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk670ue7Z0YZ"
      },
      "source": [
        "Next, we will split our data by extracting the 10 test subjects we defined here:\n",
        "\n",
        "[skin_test_subjects.txt]\n",
        "\n",
        "We will create an additional column in `meta` called `subset`, which indicate whether this sample belongs to `train` or `test`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esDtmFe37tza"
      },
      "source": [
        "Next, we will split our data by extracting the 10 test subjects we defined here:\n",
        "\n",
        "[skin_test_subjects.txt]\n",
        "We will create an additional column in `meta` called `subset`, which indicate whether this sample belongs to `train` or `test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQFWbwa-i3Yy",
        "outputId": "72f54295-34ef-4326-ea62-be91b10eb00e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    GTEX-11VI4\n",
              "1    GTEX-11WQK\n",
              "2    GTEX-1212Z\n",
              "3    GTEX-12696\n",
              "4    GTEX-1269C\n",
              "5    GTEX-14PK6\n",
              "6    GTEX-16BQI\n",
              "7    GTEX-V1D1-\n",
              "8    GTEX-X8HC-\n",
              "9    GTEX-ZYT6-\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_subject_id = pd.read_csv(\n",
        "    DATA / \"skin_test_subjects.txt\", sep=\"\\t\", header=None\n",
        ")[0]\n",
        "test_subject_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui84gx5sZBdh"
      },
      "outputs": [],
      "source": [
        "# define train and test set\n",
        "meta[\"subset\"] = \"train\"\n",
        "meta.loc[meta.subject_id.isin(test_subject_id), \"subset\"] = \"test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mD1x5a1dUam"
      },
      "source": [
        "As a sanity check, let's see how many samples we have in each class after the split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBpq7fQAbbR_",
        "outputId": "3a8e76ec-1b90-4688-ddad-83f54d8f7333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subset  sun_exposed\n",
              "test    0              10\n",
              "        1              10\n",
              "train   0              42\n",
              "        1              50\n",
              "dtype: int64"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta.groupby([\"subset\", \"sun_exposed\"]).size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZDF5er1Iaq0"
      },
      "source": [
        "_You would notice that here we are working with a very small data set. Ideally in a machine learning use case we would like to have at least 100 samples per each class for training, while also have much more testing samples. This exercise is just a toy example for you to practice how to prepare data and apply AutoML. It is definitely not an ideal use case. Therefore, you might notice some behaviors of the models are counter-intuitive or the outcomes might not be meaningful._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRsfR-hnfBTI"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LjjwB2S__xE"
      },
      "source": [
        "To build our first model. Let's use the differential expressed genes we found in Problem 1 as the features. Use only genes with `logFC > 1` or `logFC < -1` (and FDR < 0.05 as we already selected). create `x_train`, `x_test` from RNAseq data (with selected genes as columns and training samples and testing samples as rows respectively), and `y_train`, `y_test` vector from the `sun_exposed` column of `meta`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rguIeaUn7wLp"
      },
      "outputs": [],
      "source": [
        "#=======================================================\n",
        "# Your code here\n",
        "# Create x_train, x_test, y_train, y_test\n",
        "#======================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN_hp3HwC3Hv"
      },
      "source": [
        "### Training a classifier using AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qeSQp0sC_tj"
      },
      "source": [
        "Again follow what we did in class. Using the features selected above, we will build a model using AutoML. You can use the `preset` of `good_quality_faster_inference_only_refit` to save time and space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeN0a4KQ7we7"
      },
      "outputs": [],
      "source": [
        "#===========================================================================\n",
        "# Your code here\n",
        "# Train a classification model using AutoGluon TabularPrediction module \n",
        "#==========================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhIzH-gWDSbe"
      },
      "source": [
        "Once the model is trained, evaluate the best model from AutoML on test set using the performance scores function provided below, like what we did in class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnzalB9XBV9C"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, \n",
        "                             roc_auc_score, f1_score)\n",
        "def performance_scores(y_true, y_pred_score, y_pred=None):\n",
        "    # We can find which class has the highest score as its predicted class\n",
        "    if y_pred is None:\n",
        "        y_pred = y_pred_score.idxmax(axis=1)\n",
        "        \n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
        "        \"auroc\": roc_auc_score(y_true, y_pred_score[:, 1], average=\"weighted\",\n",
        "                               multi_class=\"ovr\"),\n",
        "        \"f1\": f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHINn9gd707K"
      },
      "outputs": [],
      "source": [
        "#===========================================================\n",
        "# Your code here\n",
        "# Calculate the test performance scores of your model\n",
        "#==========================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okONyxrpJvFU"
      },
      "source": [
        "Now also plot the confusion matrix to show correct and incorrect predictions in the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZguxNAte75qn"
      },
      "outputs": [],
      "source": [
        "#============================================================================\n",
        "# Your code here\n",
        "# Plot confusion matrix for the trained model\n",
        "#============================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OniOYlzEOSn"
      },
      "source": [
        "### Answer the following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efSKXkmTEZpb"
      },
      "source": [
        "#### 2.2. Try to investigate the model performance you by extracting the following information: What is the top model in the AutoML leaderboard? What are the validation scores of the best AutoML model? What are the most important features in the AutoML model?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY40Koqh7-ZH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
